{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "columns = [col for col in df.columns if df[col].dtype in [np.float64, np.int64]]\n",
    "X = df[columns]\n",
    "X = X.drop('SalePrice', axis = 1)\n",
    "\n",
    "\n",
    "# Impute null values\n",
    "for col in X:\n",
    "    median = X[col].median()\n",
    "    X[col].fillna(value = median, inplace = True)\n",
    "\n",
    "# Create y\n",
    "y = df.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150263031716833\n",
      "0.7969891977997344\n",
      "1107301266.1736867\n",
      "1474366811.104531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg = LinearRegression()\n",
    "\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print(linreg.score(X_train, y_train)) #R2 for training set\n",
    "print(linreg.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, linreg.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, linreg.predict(X_test))) #MSE for testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8017017507690365\n",
      "0.8410975703781115\n",
      "1278054811.650263\n",
      "936130871.1556543\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print(linreg.score(X_train, y_train)) #R2 for training set\n",
    "print(linreg.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, linreg.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, linreg.predict(X_test))) #MSE for testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "\n",
    "features_cat = [col for col in df.columns if df[col].dtype in [np.object]]\n",
    "X_cat = df[features_cat]\n",
    "\n",
    "np.shape(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 209)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat, drop_first = True)\n",
    "\n",
    "np.shape(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([pd.DataFrame(X_scaled),X_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9409586655434856\n",
      "-1.008602859083722e+17\n",
      "376229283.6022283\n",
      "6.162807010933384e+26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.04281490e+03, -2.08845380e+03,  9.58654353e+02,  7.03963443e+03,\n",
       "        8.79122205e+03,  7.17475121e+03,  9.61498812e+03,  2.09103406e+03,\n",
       "        3.92917012e+03,  5.95460170e+16,  2.10610839e+16,  5.76880671e+16,\n",
       "       -5.72752994e+16,  1.69194291e+16,  1.91051375e+16,  2.12804157e+15,\n",
       "       -2.29982154e+16,  1.51963401e+03,  6.02680993e+02,  1.93940491e+03,\n",
       "       -4.52243190e+02, -1.60801559e+03, -2.66448356e+03, -2.64043616e+02,\n",
       "        3.54344002e+03, -1.84379039e+03,  3.72711550e+03,  3.22733185e+03,\n",
       "        3.09354357e+03,  2.80335357e+02,  1.01092422e+03,  9.56529929e+02,\n",
       "        1.58979060e+03,  1.64489840e+04,  7.19106050e+02, -1.11631977e+03,\n",
       "       -1.26968558e+03,  3.43105668e+04,  1.29869188e+04,  1.86813994e+04,\n",
       "        1.85888229e+04,  3.72960026e+04, -2.58384283e+03,  1.38568297e+03,\n",
       "        1.62140814e+03,  2.39674516e+03,  1.05082626e+04,  1.06692335e+03,\n",
       "        1.10895591e+04, -4.92505059e+04,  1.09617640e+04, -9.40560152e+03,\n",
       "       -4.32387099e+04, -1.90026621e+03,  1.15160030e+04, -2.73677182e+04,\n",
       "       -6.36940593e+03, -2.62020401e+03, -8.19709440e+03, -1.69803402e+04,\n",
       "       -1.06599943e+04,  1.46441018e+04, -2.27739103e+04, -8.23218081e+03,\n",
       "       -1.64385354e+04, -1.22544064e+04, -2.34301054e+04, -1.70224200e+04,\n",
       "        2.19863814e+04, -1.85306916e+04,  2.72132091e+04,  1.81476138e+04,\n",
       "       -1.77971095e+04, -1.13146581e+04, -1.14644683e+04, -1.92435747e+03,\n",
       "       -7.96602421e+03,  5.68580430e+04, -5.31385005e+03,  7.68213979e+03,\n",
       "        6.10928837e+03,  1.52490282e+04,  3.92777327e+03,  1.02663669e+04,\n",
       "       -1.05417073e+04,  1.07614624e+04, -7.98189731e+03,  2.39523021e+04,\n",
       "       -2.38128152e+14, -2.38128152e+14, -2.38128152e+14, -2.38128152e+14,\n",
       "        4.71891664e+13, -2.38128152e+14, -2.38128152e+14, -1.60277054e+03,\n",
       "       -3.01752857e+03, -2.00445244e+04, -1.82989712e+04,  1.09307879e+04,\n",
       "        8.36594946e+03, -1.61635313e+04, -1.91853291e+04, -4.75240620e+03,\n",
       "        5.40411549e+03,  4.16972996e+03, -9.84222573e+02,  4.36146907e+03,\n",
       "       -1.41815941e+03,  1.01065234e+04, -5.83382139e+13,  2.35110230e+14,\n",
       "        2.35110230e+14,  2.35110230e+14,  2.35110230e+14,  2.35110230e+14,\n",
       "        2.35110230e+14,  2.35110230e+14, -2.81375919e+04, -3.95872295e+04,\n",
       "        1.04575998e+03,  4.14904784e+14, -2.06941751e+04, -1.92589393e+04,\n",
       "        3.64913363e+13, -1.96000830e+04, -2.12411018e+04, -9.91249026e+03,\n",
       "       -9.03590054e+02, -2.56686470e+04, -2.10366571e+04, -1.41198460e+04,\n",
       "        1.25789602e+04,  1.16683642e+04,  7.14273757e+03, -4.14904784e+14,\n",
       "        1.94410197e+04,  1.08708973e+04,  9.93880769e+03,  1.72387113e+04,\n",
       "       -1.50391855e+04,  1.02853607e+04, -9.47445299e+03,  2.67096353e+02,\n",
       "        2.15051103e+04,  1.69293442e+04,  5.32390728e+03,  5.95879188e+02,\n",
       "        2.32283495e+02,  5.45048335e+03, -9.20675286e+03, -2.39777978e+04,\n",
       "       -2.48085909e+04,  1.60267439e+03,  3.49249910e+03,  1.06019597e+12,\n",
       "        6.53818169e+03,  4.98437169e+03,  5.60382591e+03, -7.20413399e+03,\n",
       "        1.98875916e+03, -2.51814192e+04, -1.36903803e+04, -1.58713653e+04,\n",
       "       -1.48573165e+04, -5.73965712e+01,  6.16401191e+04, -9.79342704e+02,\n",
       "        9.06855688e+03, -2.92139641e+03, -4.68605507e+03,  2.25410311e+03,\n",
       "        7.06060711e+03, -5.81390881e+03, -2.86197622e+02,  1.84688614e+03,\n",
       "       -6.58905281e+03,  9.58490442e+03,  1.17512021e+02,  9.32034248e+02,\n",
       "        5.70800246e+03,  2.64098574e+03,  3.45212757e+03, -5.18644725e+03,\n",
       "        4.91509721e+08,  1.45322541e+04, -3.94573256e+02, -2.76539388e+03,\n",
       "       -7.05186449e+03, -3.75509005e+03, -1.44217539e+02,  4.01392590e+03,\n",
       "        1.64481931e+04, -1.65976673e+04, -4.04513876e+03, -2.16103271e+04,\n",
       "       -2.37114267e+04, -2.34678797e+04, -1.43275709e+04,  1.50974990e+04,\n",
       "        1.36784115e+04,  8.48368132e+03, -4.57063333e+04,  2.15560778e+04,\n",
       "       -7.40438724e+03, -3.85822754e+03,  5.06501428e+02, -6.47184245e+03,\n",
       "        1.62733566e+04,  1.60828289e+04,  1.19286276e+04,  1.86283121e+04,\n",
       "        1.80182314e+04, -3.68716425e+03, -2.03275757e+03, -1.12088367e+05,\n",
       "       -9.84350924e+04, -1.23997356e+05, -1.06506972e+05,  7.69347523e+04,\n",
       "        7.98770771e+04,  8.49874330e+04,  8.11468319e+04, -4.99889057e+03,\n",
       "       -8.81219716e+02, -2.48175850e+05,  1.60000000e+01,  1.31169990e+03,\n",
       "        1.04027490e+03, -2.32956845e+03,  7.29306547e+03,  6.69398371e+01,\n",
       "        1.58966969e+04,  2.49785087e+04,  4.38396861e+04,  1.05009192e+04,\n",
       "        6.57506590e+03,  2.64415394e+03, -1.85436005e+04,  5.29571315e+03,\n",
       "       -4.65183605e+03, -2.90862687e+04,  4.16420264e+03,  3.32664877e+03,\n",
       "        8.44626884e+03,  3.48476178e+04])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(linreg.score(X_train, y_train)) #R2 for training set\n",
    "print(linreg.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, linreg.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, linreg.predict(X_test))) #MSE for testing set\n",
    "\n",
    "linreg.coef_\n",
    "\n",
    "#OVERFITTED!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408989961876238\n",
      "0.5467639838199467\n",
      "376609514.82863265\n",
      "2769381499.3341107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.00546925e+03, -2.34644012e+03,  1.02454547e+03,  6.81229123e+03,\n",
       "        8.75526387e+03,  7.09439785e+03,  9.73430999e+03,  2.08925376e+03,\n",
       "        3.80222806e+03,  9.46547069e+03,  3.81167014e+03,  3.03150502e+03,\n",
       "        3.58369930e+03,  1.45386217e+04,  2.55484544e+04,  1.18860570e+03,\n",
       "        5.06890586e+03,  1.56619278e+03,  6.29775181e+02,  1.97128111e+03,\n",
       "       -4.34949135e+02, -1.75628166e+03, -2.57571049e+03, -4.72610370e+01,\n",
       "        3.56486149e+03, -1.82622971e+03,  3.90599861e+03,  3.17929896e+03,\n",
       "        3.08417454e+03,  3.36514914e+02,  9.88522755e+02,  9.91749494e+02,\n",
       "        1.64475215e+03,  1.63054029e+04,  1.03252770e+03, -1.20091921e+03,\n",
       "       -1.25226318e+03,  3.25602377e+04,  1.04761572e+04,  1.73678267e+04,\n",
       "        1.70150367e+04,  3.69493251e+04, -2.69806456e+03,  1.86535527e+03,\n",
       "        1.61666321e+03,  2.36387708e+03,  1.04013430e+04,  1.16079590e+03,\n",
       "        1.09802987e+04, -4.73314588e+04,  1.11645166e+04, -8.94092611e+03,\n",
       "       -4.20190255e+04, -1.65070109e+03,  1.13927152e+04, -2.49590190e+04,\n",
       "       -3.93346431e+03, -4.04911757e+02, -5.70179798e+03, -1.51513048e+04,\n",
       "       -8.90757444e+03,  1.62654670e+04, -2.06428393e+04, -6.40737452e+03,\n",
       "       -1.41301441e+04, -1.01361644e+04, -2.16217366e+04, -1.48078480e+04,\n",
       "        2.35373529e+04, -1.64878505e+04,  2.91509128e+04,  1.96804127e+04,\n",
       "       -1.54197144e+04, -1.01364881e+04, -9.32836935e+03, -2.70435325e+02,\n",
       "       -5.94375397e+03,  5.79893993e+04, -3.51226532e+03,  8.88686067e+03,\n",
       "        5.25558048e+03,  1.44638695e+04,  2.94581876e+03,  8.98390698e+03,\n",
       "       -1.12244621e+04,  1.00333160e+04, -8.02732819e+03,  2.36984524e+04,\n",
       "        8.73252073e+03, -3.07872319e+02,  5.84022332e+04, -2.08752464e+05,\n",
       "        0.00000000e+00, -1.18099866e+04,  7.75187911e+03, -1.42381443e+03,\n",
       "       -2.90365953e+03, -1.89883904e+04, -1.69594121e+04,  1.05887777e+04,\n",
       "        8.24178071e+03, -1.13430258e+04, -1.84452815e+04, -4.52715617e+03,\n",
       "        5.49604827e+03,  4.51449339e+03, -1.47515939e+03,  3.21903918e+03,\n",
       "       -1.87989496e+03,  1.03342583e+04,  0.00000000e+00, -5.02949616e+02,\n",
       "        5.51887823e+04,  4.25712418e+04, -2.17528742e+04,  0.00000000e+00,\n",
       "       -1.70957352e+04,  5.62296370e+04, -1.86944767e+04, -2.94754459e+04,\n",
       "        7.77060997e+03, -1.00154147e+03, -1.30377325e+04, -1.16110380e+04,\n",
       "        0.00000000e+00, -1.16654561e+04, -1.36564632e+04, -1.72500320e+03,\n",
       "        4.86648836e+03, -1.89706699e+04, -1.36200801e+04, -7.24831816e+03,\n",
       "        4.44818875e+03,  3.44148616e+03,  8.33095476e+02, -1.36444620e+04,\n",
       "        1.24084533e+04,  3.96652766e+03,  3.39797018e+03,  9.92311599e+03,\n",
       "       -1.96828795e+04,  3.60226715e+03, -1.52287226e+04, -4.36337161e+03,\n",
       "        1.55270195e+04,  1.03155355e+04, -7.52372920e+02,  4.93103367e+02,\n",
       "        1.20691525e+02,  5.20134454e+03, -9.42770606e+03, -2.36911499e+04,\n",
       "       -2.45345890e+04, -6.86311188e+02,  1.18273377e+03,  0.00000000e+00,\n",
       "        3.98848898e+03,  4.52438597e+03,  5.10221602e+03, -6.79597572e+03,\n",
       "        1.27880868e+03, -2.49507222e+04, -1.37022138e+04, -1.57790142e+04,\n",
       "       -1.47652094e+04,  0.00000000e+00,  5.54368483e+04, -8.79259417e+02,\n",
       "        9.12175304e+03, -2.76198826e+03, -4.75310925e+03,  2.37004781e+03,\n",
       "        6.88312040e+03, -5.86736567e+03, -3.91010444e+02,  1.84004339e+03,\n",
       "       -6.68971389e+03,  8.99370888e+03,  0.00000000e+00,  6.22312931e+02,\n",
       "        5.43950614e+03,  3.19095714e+02,  2.46773921e+02, -7.83079509e+03,\n",
       "        0.00000000e+00,  1.07494920e+04, -1.91988502e+02, -2.88387031e+03,\n",
       "       -5.89471178e+03, -3.84414886e+03, -4.38342554e+02,  3.86082185e+03,\n",
       "        1.61192077e+04, -8.88990090e+03, -4.02661418e+03, -2.12897163e+04,\n",
       "       -2.37678657e+04, -2.35580220e+04, -1.48505563e+04,  1.43184603e+04,\n",
       "        1.34882662e+04,  8.07830148e+03, -4.23033394e+04,  2.09711840e+04,\n",
       "       -7.40776773e+03, -3.91905052e+03,  4.56247934e+01, -6.50379443e+03,\n",
       "        1.51624694e+04,  1.45667256e+04,  1.08769001e+04,  1.58647415e+04,\n",
       "        1.68184747e+04, -3.65458908e+03, -1.80355458e+03, -9.15552110e+04,\n",
       "       -7.82033020e+04, -1.01399276e+05, -8.65736782e+04,  5.72417115e+04,\n",
       "        5.92819371e+04,  6.32855156e+04,  6.17061606e+04, -4.30570274e+03,\n",
       "       -6.07482828e+02, -2.44366276e+05,  0.00000000e+00,  1.49017597e+03,\n",
       "        1.13029970e+03, -2.14873191e+03,  2.59109162e+03, -3.75168303e+02,\n",
       "        1.02414946e+04,  2.45343400e+04,  4.24411852e+04,  1.04810673e+04,\n",
       "        6.35498402e+03,  2.22635244e+03, -1.72513079e+04,  5.19346637e+03,\n",
       "       -4.79151927e+03, -2.35207649e+04,  3.63019362e+03,  3.12154615e+03,\n",
       "        8.62368567e+03,  3.37004640e+04])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso regression is very similar to Ridge regression\n",
    "#except that the magnitude of the coefficients are not squared in the penalty term\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(lasso.score(X_train, y_train)) #R2 for training set\n",
    "print(lasso.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, lasso.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, lasso.predict(X_test))) #MSE for testing set\n",
    "\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295600372615882\n",
      "0.8013427483021793\n",
      "457164716.08595544\n",
      "1130514318.143185\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=10)\n",
    "\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(lasso.score(X_train, y_train)) #R2 for training set\n",
    "print(lasso.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, lasso.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, lasso.predict(X_test))) #MSE for testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121095201942101\n",
      "0.883725452494536\n",
      "570420890.1456664\n",
      "661692637.2790899\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression puts a constraint on the coefficients m\n",
    "# this means that large coefficients penalize the optimization function\n",
    "\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(ridge.score(X_train, y_train)) #R2 for training set\n",
    "print(ridge.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, ridge.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, ridge.predict(X_test))) #MSE for testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908897245386075\n",
      "0.8942918588976493\n",
      "708140182.9897192\n",
      "601561564.1471125\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(ridge.score(X_train, y_train)) #R2 for training set\n",
    "print(ridge.score(X_test, y_test)) #R2 for testing set\n",
    "\n",
    "print(mean_squared_error(y_train, ridge.predict(X_train))) #MSE for training set\n",
    "print(mean_squared_error(y_test, ridge.predict(X_test))) #MSE for testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "- penalising the coefficients improves R2 and avoids overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# number of Ridge params almost zero\n",
    "print(sum(abs(ridge.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# number of Lasso params almost zero\n",
    "print(sum(abs(lasso.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
