{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'train_users_2.csv' does not exist: b'train_users_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1e7c47665df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_users_2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train_users_2.csv' does not exist: b'train_users_2.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_users_2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining 'sessions' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sessions = pd.read_csv('sessions.csv')\n",
    "#sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefining target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining target\n",
    "#user who made a booking = 1\n",
    "#user who did not make a booking = 0\n",
    "df.loc[(df['country_destination'] != 'NDF','country_destination')] = 1\n",
    "df.loc[(df['country_destination'] == 'NDF','country_destination')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming target column\n",
    "df = df.rename(columns={'country_destination':'target'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop date_first_booking - this column copies the target column and would cause data leakage\n",
    "df.drop('date_first_booking',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating date_account_created and timestamp_first_active columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_account_created']= pd.to_datetime(df['date_account_created']) \n",
    "df['timestamp_first_active']= pd.to_datetime(df['timestamp_first_active'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # timestamp_first_active shows incorrect dates, NEEDS FIXING!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.isna().sum()\n",
    "#this column has 87990 missing values, that is more than a third of the dataset\n",
    "\n",
    "#mean age before cleaning: 49.6\n",
    "#median age before cleaning: 34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.value_counts()\n",
    "#there are numerous errors in this column and many missing values\n",
    "#for the sake of simplicity, remove all rows with errors and replace missing values with median age\n",
    "\n",
    "#finding all ages over 110\n",
    "indexNames = df[df['age'] > 110].index\n",
    "\n",
    "#deleting these row indexes from dataFrame\n",
    "df.drop(indexNames, inplace=True)\n",
    "\n",
    "#replacing NaNs with median\n",
    "df['age'].fillna((df['age'].median()), inplace=True)\n",
    "#Note - replacing the NaNs with median did not affect the median of target users. This suggest that age is not\n",
    "#defining element\n",
    "\n",
    "df.age.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean age after cleaning: 35 - significantly lower from 49 due to removing outliers\n",
    "* Meadian age after cleaning: 34 - stayed the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.signup_flow.value_counts()\n",
    "#the page a user came to signup up from\n",
    "#What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()\n",
    "#since vast majority is english, this column might not bring much information.\n",
    "#Also, it would create many caterogies and increase the dimensionality\n",
    "#For now, I will drop whis column from the dataset\n",
    "\n",
    "#UPDATE = I will keep this columns for experimentation\n",
    "#df.drop('language', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.affiliate_provider.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_affiliate_tracked.isna().sum()\n",
    "#whats the first marketing the user interacted with before the signing up\n",
    "#6030 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_affiliate_tracked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing NaNs with the most common value 'untracked\"'\n",
    "df.first_affiliate_tracked.fillna('untracked',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_browser.value_counts()\n",
    "#many under-represented categories\n",
    "#top 6 browsers = 209 509 users = 98.5% of users\n",
    "#I will turn the remaining categories into 'other'\n",
    "#UPDATE - For experiment I will keep this column as it is\n",
    "\n",
    "#df.loc[(df.first_browser != 'Chrome') & (df.first_browser != 'Safari')& (df.first_browser != 'Firefox')& (df.first_browser != '-unknown-')& (df.first_browser != 'Mobile Safari')& (df.first_browser != 'IE'),'first_browser']='other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing 'sessions' dataset (removed for insufficient data - sessions data only from the start of 2014 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_id = pd.Series(sessions.user_id.unique())\n",
    "#df_id = pd.Series(df.id)\n",
    "\n",
    "#print(len(s_id.unique()))\n",
    "#print(len(df_id.unique()))\n",
    "#each dataset has a different number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try merging the data to find whether we have any intersection\n",
    "#s_id = s_id.rename('id')\n",
    "#intersection = pd.merge(s_id, df_id, how='inner')\n",
    "#len(intersection)\n",
    "#it seems that we have 73 680 common users in each datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_count = sessions.groupby(['user_id'])['action'].nunique() # number of unique actions a user performed on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am mergin the unique numbers of actions per user with our main dataset\n",
    "#action_count = pd.DataFrame(action_count)\n",
    "#action_count = action_count.rename(columns={'0':'unique_sessions'})\n",
    "#action_count = action_count.reset_index()\n",
    "#action_count = action_count.rename(columns={'user_id':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the column 'action' will now contain a number of unique action a user has performed on the website\n",
    "#df = pd.merge(df,action_count,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.xlabel('Target', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Number of users who did and did not book',fontsize=20)\n",
    "plt.hist(df.target,color='dodgerblue',rwidth=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in this histogram, just over XXX users from the dataset did make a booking and around XXX did not. This suggests we have a target class imbalance which might have to be rectified by upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who are AirBnb customers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at the data from users who made a booking on the website and compare it with users who did not book. This might help us find indication of what are the important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating separate datasets for users who did and did not book\n",
    "\n",
    "#'yes booking = yb'\n",
    "yb = df.loc[df.target == 1]\n",
    "\n",
    "#'no booking = nb'\n",
    "nb = df.loc[df.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.xlabel('Age', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Age distribution',fontsize=20)\n",
    "plt.hist(yb.age,color='darkorange',rwidth=5,alpha=1,label='Booked',bins=20)\n",
    "plt.hist(nb.age,color='dodgerblue',rwidth=5,alpha=0.5,label='Did not book',bins=20)\n",
    "plt.legend();\n",
    "\n",
    "print('Median age of users who booked: '+str(round(yb.age.median(),2)))\n",
    "print('Median age of users who did not book: '+str(round(nb.age.median(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The age of users who did not book is more concentrated around the mean age (it has a strong peak in ages between 35 to 40).\n",
    "* The peak of users who booked is in the previous bin, but the peak is less strong. \n",
    "* Most users are between 25 to 40. Both distributions have positive/right skew. \n",
    "* Median for both distributions is almost identical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x='gender',hue='target',data=df)\n",
    "plt.xlabel('Gender', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Gender',fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The distribution of gender categories is pretty equal among users who made a booking, just below 10 000 each.\n",
    "* Users whose gender is unknown were twice as likely not to make a booking compared to other gender categories.\n",
    "* This seems to be a significant factor for determining a user who will not make a booking. \n",
    "* Also, if take into consideration the class imbalance mentioned above, users whose gender we know are generally more likely to make a booking than not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign-up method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x='signup_method',hue='target',data=df)\n",
    "plt.xlabel('Sign-up Method', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Sign-up method',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When did users create their accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_ac_created_yb = dict(yb.date_account_created.value_counts())\n",
    "dates_ac_created_nb = dict(nb.date_account_created.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ac_created_yb = dict()\n",
    "\n",
    "for key in sorted(dates_ac_created_yb.keys()):\n",
    "    dict_ac_created_yb.update({key:dates_ac_created_yb[key]})\n",
    "\n",
    "dict_ac_created_nb = dict()\n",
    "\n",
    "for key in sorted(dates_ac_created_nb.keys()):\n",
    "    dict_ac_created_nb.update({key:dates_ac_created_nb[key]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ac_created_yb = pd.Series(dict_ac_created_yb)\n",
    "series_ac_created_nb = pd.Series(dict_ac_created_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(18,7), sharey=True)\n",
    "axs[0].plot(series_ac_created_yb,color='darkorange')\n",
    "axs[0].set_title('Users with booking',fontsize=15)\n",
    "axs[1].plot(series_ac_created_nb,color='dodgerblue')\n",
    "axs[1].set_title('Users without booking',fontsize=15)\n",
    "fig.suptitle('Number of new accounts daily',fontsize=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "sns.countplot(x='first_device_type',hue='target',data=df)\n",
    "plt.xlabel('Device', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Device',fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By far the most popular devices as Mac and Windows desktop computers.\n",
    "* Users of Mac Desktop are more likely to make a booking due to a small difference between users who booked it who did not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign-up Flow (the page a user came to signup up from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "sns.countplot(x='signup_flow',hue='target',data=df)\n",
    "plt.xlabel('Source', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Sign-up Flow - where users came from to sign up',fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unfortunately we don't know what sources there numbers represent, but most common by far is '0'\n",
    "* Sources number 2 and 3 are most effective at converting users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "sns.countplot(x='affiliate_channel',hue='target',data=df)\n",
    "plt.xlabel('Channel', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Affiliate Channel - type of paid marketing',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling the minority class (0) to fix class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "#yb = class 1 = minority class\n",
    "#nb = class 0 = majority class\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(yb,\n",
    "                             \treplace=True, \t# sample with replacement\n",
    "                             \tn_samples=len(nb),    # to match majority class\n",
    "                             \trandom_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df= pd.concat([nb, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df.target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.xlabel('Target', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.title('Number of users who did and did not book',fontsize=20)\n",
    "plt.hist(df.target,color='dodgerblue',rwidth=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unneccesary columns\n",
    "df.drop('id',axis=1, inplace= True)\n",
    "\n",
    "df.drop('date_account_created',axis=1, inplace= True)\n",
    "\n",
    "df.drop('timestamp_first_active',axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['gender', 'signup_method','signup_flow','language','affiliate_channel',\n",
    "       'affiliate_provider', 'first_affiliate_tracked', 'signup_app',\n",
    "       'first_device_type', 'first_browser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Splitting an initial testing set (10% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am going to cut away a random 10% of the dataset for final testing.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_initial_split = df.drop('target',axis=1)\n",
    "y_initial_split = df.target\n",
    "\n",
    "#is = 'initial split'\n",
    "X_train_is, X_test_is, y_train_is, y_test_is = train_test_split(X_initial_split, y_initial_split, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_is)\n",
    "# this is 90% of our original dataset\n",
    "# I will now overwrite this and will be using this to build all following models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging our dataset back together\n",
    "df = pd.concat([X_train_is,y_train_is],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting baseline simple model (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for PCA and scaling data\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data for PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting PCA components\n",
    "\n",
    "pca_1 = PCA(n_components=110)\n",
    "pca_2 = PCA(n_components=120)\n",
    "pca_3 = PCA(n_components=130)\n",
    "\n",
    "principalComponents = pca_1.fit_transform(scaled_X_train)\n",
    "principalComponents = pca_2.fit_transform(scaled_X_train)\n",
    "principalComponents = pca_3.fit_transform(scaled_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at explained variance ratio of different number of components\n",
    "print(np.sum(pca_1.explained_variance_ratio_))\n",
    "print(np.sum(pca_2.explained_variance_ratio_))\n",
    "print(np.sum(pca_3.explained_variance_ratio_))\n",
    "\n",
    "#120 components explains 97% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASELINE MODEL WITHOUT GRIDSEARCH\n",
    "\n",
    "pipe_baseline = Pipeline([('scl', MinMaxScaler()),\n",
    "                  ('pca', PCA(n_components=120)),\n",
    "                  ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "pipe_baseline.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe_baseline.score(X_train,y_train))\n",
    "print(pipe_baseline.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model successfully classified 69% of our testing data\n",
    "Training accuracy was 77%, which suggests this model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIAGNOsticks\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "pipe_baseline_pred = pipe_baseline.predict(X_test)\n",
    "print(classification_report(y_test, pipe_baseline_pred))\n",
    "print(confusion_matrix(y_test, pipe_baseline_pred, labels=[1,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pipe_baseline_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pipe_baseline.predict(X_test))\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try this model with gridsearch\n",
    "pipe_baseline_grid = Pipeline([('scl', MinMaxScaler()),\n",
    "                  ('pca', PCA(n_components=120)),\n",
    "                  ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params\n",
    "param_baseline_grid = [ \n",
    "  {'clf__n_estimators': [30,50,80],\n",
    "   'clf__criterion': ['gini','entropy'], \n",
    "   'clf__max_depth': [20,40],  \n",
    "   'clf__min_samples_leaf':[0.02,0.002],  \n",
    "  }]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_baseline_grid,\n",
    "            param_grid=param_baseline_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_rf.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rf.best_params_)\n",
    "\n",
    "# {'clf__criterion': 'gini', 'clf__max_depth': 20, 'clf__min_samples_leaf': 0.1, 'clf__n_estimators': 100}\n",
    "# {'clf__criterion': 'gini', 'clf__max_depth': 20, 'clf__min_samples_leaf': 0.02, 'clf__n_estimators': 100}\n",
    "#  {'clf__criterion': 'gini', 'clf__max_depth': 20, 'clf__min_samples_leaf': 0.002, 'clf__n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best accuracy: 0.677\n",
    "\n",
    "#Best params:\n",
    "# {'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__min_samples_leaf': 0.002, 'clf__n_estimators': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf_preds = gs_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gs_rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,gs_rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, gs_rf_preds)\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try a different model\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# Fit XGBClassifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test sets\n",
    "training_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "# Accuracy of training and test sets\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [40],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'n_estimators': [30],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid_clf = GridSearchCV(clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "test_preds = grid_clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print('')\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xboost_preds = grid_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_for_classification as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.model_stats(y_test,xboost_preds,'XBOOST',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-learn-env] *",
   "language": "python",
   "name": "conda-env-conda-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
