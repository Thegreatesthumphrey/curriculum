{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lecture, you'll practice implementing the Naive Bayes algorithm on your own.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:  \n",
    "\n",
    "* Implement document classification using Naive Bayes\n",
    "* Understand the need for the Laplacian smoothing correction\n",
    "* Explain how to code a bag of words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset\n",
    "\n",
    "To start, import the dataset stored in the text file `SMSSpamCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0.8659368269921034, 'spam': 0.13406317300789664}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define p_classes\n",
    "\n",
    "p_classes = dict(df2.label.value_counts(normalize=True))\n",
    "p_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for Class Imbalance\n",
    "\n",
    "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df['label'].isin(['ham','spam'])]\n",
    "df2.label.value_counts()\n",
    "\n",
    "#ham: 4825\n",
    "#spam:747\n",
    "\n",
    "less_ham = df2[df2['label'].isin(['ham'])]\n",
    "less_ham = less_ham.iloc[0:747]\n",
    "\n",
    "len(less_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ham</td>\n",
       "      <td>K tell me anything about you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ham</td>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup... Ok i go home look at the timings then i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oops, I'll let you know when my roommate's done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ham</td>\n",
       "      <td>I see the letter B on my car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>spam</td>\n",
       "      <td>u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>spam</td>\n",
       "      <td>Call 09095350301 and send our girls into eroti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>spam</td>\n",
       "      <td>Camera - You are awarded a SiPix Digital Camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>spam</td>\n",
       "      <td>A £400 XMAS REWARD IS WAITING FOR YOU! Our com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>spam</td>\n",
       "      <td>IMPORTANT MESSAGE. This is a final contact att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>spam</td>\n",
       "      <td>dating:i have had two of these. Only started a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>spam</td>\n",
       "      <td>The current leading bid is 151. To pause this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry to the gr8prizes wkly comp 4 a chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new message. Call 0207-083-6089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>spam</td>\n",
       "      <td>Santa Calling! Would your little ones like a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have won a guaranteed 32000 award or maybe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>spam</td>\n",
       "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>spam</td>\n",
       "      <td>For the most sparkling shopping breaks from 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>spam</td>\n",
       "      <td>December only! Had your mobile 11mths+? You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>spam</td>\n",
       "      <td>Txt: CALL to No: 86888 &amp; claim your reward of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>spam</td>\n",
       "      <td>http//tms. widelive.com/index. wml?id=820554ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>spam</td>\n",
       "      <td>Get your garden ready for summer with a FREE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! Last weekend's draw shows that you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT We are trying to contact you Last weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>spam</td>\n",
       "      <td>2p per min to call Germany 08448350055 from yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>spam</td>\n",
       "      <td>Marvel Mobile Play the official Ultimate Spide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS SERVICES. for your inclusive text credits,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 07808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are awarded a SiPix Digital Camera! call 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for shows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...\n",
       "13     ham  I've been searching for the right words to tha...\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "16     ham                         Oh k...i'm watching here:)\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18     ham  Fine if thats the way u feel. Thats the way ...\n",
       "20     ham          Is that seriously how you spell his name?\n",
       "21     ham    I‘m going to try for 2 months ha ha only joking\n",
       "22     ham  So ü pay first lar... Then when is da stock co...\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...\n",
       "26     ham                     Lol your always so convincing.\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
       "30     ham  Wait that's still not all that clear, were you...\n",
       "31     ham  Yeah he got in at 2 and was v apologetic. n ha...\n",
       "32     ham                      K tell me anything about you.\n",
       "33     ham  For fear of fainting with the of all that hous...\n",
       "35     ham  Yup... Ok i go home look at the timings then i...\n",
       "36     ham    Oops, I'll let you know when my roommate's done\n",
       "37     ham                       I see the letter B on my car\n",
       "38     ham                        Anything lor... U decide...\n",
       "...    ...                                                ...\n",
       "5342  spam  u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...\n",
       "5364  spam  Call 09095350301 and send our girls into eroti...\n",
       "5365  spam  Camera - You are awarded a SiPix Digital Camer...\n",
       "5366  spam  A £400 XMAS REWARD IS WAITING FOR YOU! Our com...\n",
       "5368  spam  IMPORTANT MESSAGE. This is a final contact att...\n",
       "5370  spam  dating:i have had two of these. Only started a...\n",
       "5377  spam  The current leading bid is 151. To pause this ...\n",
       "5378  spam  Free entry to the gr8prizes wkly comp 4 a chan...\n",
       "5381  spam         You have 1 new message. Call 0207-083-6089\n",
       "5427  spam  Santa Calling! Would your little ones like a c...\n",
       "5443  spam  You have won a guaranteed 32000 award or maybe...\n",
       "5449  spam  Latest News! Police station toilet stolen, cop...\n",
       "5456  spam  For the most sparkling shopping breaks from 45...\n",
       "5460  spam  December only! Had your mobile 11mths+? You ar...\n",
       "5462  spam  Txt: CALL to No: 86888 & claim your reward of ...\n",
       "5466  spam  http//tms. widelive.com/index. wml?id=820554ad...\n",
       "5467  spam  Get your garden ready for summer with a FREE s...\n",
       "5468  spam  URGENT! Last weekend's draw shows that you hav...\n",
       "5482  spam  URGENT We are trying to contact you Last weeke...\n",
       "5487  spam  2p per min to call Germany 08448350055 from yo...\n",
       "5492  spam  Marvel Mobile Play the official Ultimate Spide...\n",
       "5497  spam  SMS SERVICES. for your inclusive text credits,...\n",
       "5501  spam  PRIVATE! Your 2003 Account Statement for 07808...\n",
       "5524  spam  You are awarded a SiPix Digital Camera! call 0...\n",
       "5526  spam  PRIVATE! Your 2003 Account Statement for shows...\n",
       "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_spam = df2[df2['label'].isin(['spam'])]\n",
    "\n",
    "new_df = pd.concat([less_ham,just_spam])\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2   ham  U dun say so early hor... U c already then say...\n",
       "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "4   ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.label.value_counts()\n",
    "\n",
    "#new_df = new_df.reset_index()\n",
    "#new_df = new_df.drop('index',axis=1)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0.5, 'spam': 0.5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define p_classes after editing df\n",
    "\n",
    "p_classes = dict(new_df.label.value_counts(normalize=True))\n",
    "p_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split\n",
    "\n",
    "Now implement a train test split on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = new_df.text\n",
    "y = new_df.label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([x_train, y_train], axis=1)\n",
    "test_df = pd.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Word Frequency Dictionary for Each Class\n",
    "\n",
    "Create a word frequency dictionary for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_word_freq = {} #Will be a nested dictionary of class_i : {word1:freq, word2:freq..., wordn:freq},.... class_m : {}\n",
    "classes = train_df.label.unique()\n",
    "for class_ in classes:\n",
    "    temp_df = train_df[train_df.label==class_]\n",
    "    bag = {}\n",
    "    for row in temp_df.index:\n",
    "        doc = temp_df['text'][row]\n",
    "        for word in doc.split():\n",
    "            bag[word] = bag.get(word, 0) + 1\n",
    "    class_word_freq[class_] = bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Total Corpus Words\n",
    "Calculate V, the total number of words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5991"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "for text in train_df.text:\n",
    "    for word in text.split():\n",
    "        vocabulary.add(word)\n",
    "V = len(vocabulary)\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bag of Words Function\n",
    "\n",
    "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_it(doc):\n",
    "    bag = {}\n",
    "    for word in doc.split():\n",
    "        bag[word] = bag.get(word, 0) + 1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes\n",
    "\n",
    "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
    "    bag = bag_it(doc)\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "    for class_ in class_word_freq.keys():\n",
    "        p = np.log(p_classes[class_])\n",
    "        for word in bag.keys():\n",
    "            num = bag[word]+1\n",
    "            denom = class_word_freq[class_].get(word, 0) + V\n",
    "            p += np.log(num/denom)\n",
    "        classes.append(class_)\n",
    "        posteriors.append(p)\n",
    "    if return_posteriors:\n",
    "        print(posteriors)\n",
    "    return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-184.548037428771, -184.43966173986155]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc(train_df.iloc[3]['text'], class_word_freq, p_classes, V, return_posteriors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     January Male Sale! Hot Gay chat now cheaper, c...\n",
       "label                                                 spam\n",
       "Name: 890, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out Your Classifier\n",
    "\n",
    "Finally, test out your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.763393\n",
       "True     0.236607\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_train = x_train.map(lambda x: classify_doc(x, class_word_freq, p_classes, V))\n",
    "residuals = y_train == y_hat_train\n",
    "residuals.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up\n",
    "\n",
    "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you practiced implementing Naive Bayes for document classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
